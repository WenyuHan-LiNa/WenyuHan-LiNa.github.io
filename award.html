
<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Wenyu Han| publications</title>
<meta name="description" content="Wenyu Han's academic website.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="main.css">

<link rel="canonical" href="publication">

<!-- Theming-->


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Wenyu Han</span>
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="index.html">
              About
              
            </a>
          </li>
          
          <!-- Blog -->
          <!--  <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
           -->
          <!-- Other pages -->
          
          
          
          <li class="nav-item">
              <a class="nav-link" href="publications.html">
                Publications
        
                
              </a>
          </li>

          <li class="nav-item active">
            <a class="nav-link" href="award.html">
              Awards

              <span class="sr-only">(current)</span>
              
            </a>
        </li>

          <li class="nav-item ">
              <a class="nav-link" href="Wenyu_Han_CV.pdf">
                CV                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Awards</h1>
  </header>

  <article>
    <!-- An up-to-date list is available on <a href="https://scholar.google.com/citations?user=VdlgOXoAAAAJ&hl=en" target="\_blank">Google Scholar</a> -->
<div class="publications">
  <ol class="bibliography">

 <li><div class="row">
  <div class="col-sm-2">
        <img class="img-fluid z-depth-1 rounded" src="./photos/teaser_figure_SNAC.png">
        <!-- <img class="img-fluid img-rounded" src="/home/mobile_arrangement/WenyuHan.github.io/photos/teaser_figure_SNAC.png" style="border:1px solid black" alt=""> -->
  </div>

  <div id="gao2020v1" class="col-sm-8">
    
      <div class="title">Learning </div>
      <div class="author">
                <em>Ruiqi Gao</em>, Jianwen Xie, Siyuan Huang, Yufan Ren, <a href="http://www.stat.ucla.edu/~sczhu/">Song-Chun Zhu</a>, and <a href="http://www.stat.ucla.edu/~ywu/" target="_blank">Ying Nian Wu</a>
        
      </div>
   <div class="periodical">    
        <em>The Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI)</em>, 2022
      </div>  

    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://arxiv.org/pdf/1902.03871.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>This paper proposes a representational model for image pair such as consecutive video frames that are related by local pixel displacements, in the hope that the model may shed light on motion perception in primary visual cortex (V1). The model couples the following two components. (1) The vector representations of local contents of images. (2) The matrix representations of local pixel displacements caused by the relative motions between the agent and the objects in the 3D scene. When the image frame undergoes changes due to local pixel displacements, the vectors are multiplied by the matrices that represent the local displacements. Our experiments show that our model can learn to infer local motions. Moreover, the model can learn Gabor-like filter pairs of quadrature phases.</p>
    </div>
  </div>
</div>
</li>


 <li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NeurIPS</abbr>
  </div>

  <div id="gao2021grid" class="col-sm-8">
    
      <div class="title">On Path Integration of Grid Cells: Group Representation and Isotropic Scaling</div>
      <div class="author">
                <em>Ruiqi Gao</em>, Jianwen Xie, <a href="https://sites.google.com/view/xxweineuraltheory/home">Xue-Xin Wei</a>, <a href="http://www.stat.ucla.edu/~sczhu/">Song-Chun Zhu</a>, and <a href="http://www.stat.ucla.edu/~ywu/" target="_blank">Ying Nian Wu</a>
        
      </div>
   <div class="periodical">
      
        <em>The 35th Conference on Neural Information Processing Systems</em>, 2021
  
      </div>  

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://arxiv.org/pdf/2006.10259.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      <a href="https://github.com/ruiqigao/grid-cell-path" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>Understanding how grid cells perform path integration calculations remains a fundamental problem. In this paper, we conduct theoretical analysis of a general representation model of path integration by grid cells, where the 2D self-position is encoded as a higher dimensional vector, and the 2D self-motion is represented by a general transformation of the vector. We identify two conditions on the transformation. One is a group representation condition that is necessary for path integration. The other is an isotropic scaling condition that ensures locally conformal embedding, so that the error in the vector representation translates conformally to the error in the 2D self-position. Then we investigate the simplest transformation, i.e., the linear transformation, uncover its explicit algebraic and geometric structure as matrix Lie group of rotation, and explore the connection between the isotropic scaling condition and a special class of hexagon grid patterns. Finally, with our optimization-based approach, we manage to learn hexagon grid patterns that share similar properties of the grid cells in the rodent brain. The learned model is capable of accurate long distance path integration.</p>
    </div>
    
  </div>
</div>
</li>


<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CVPR</abbr>
  </div>

  <div id="zhu2021learning" class="col-sm-8">
    
      <div class="title">Learning Neural Representation of Camera Pose with Matrix Representation of Pose Shift via View Synthesis</div>
      <div class="author">
                Yaxuan Zhu, <em>Ruiqi Gao</em>, Siyuan Huang, <a href="http://www.stat.ucla.edu/~sczhu/">Song-Chun Zhu</a>, and <a href="http://www.stat.ucla.edu/~ywu/" target="_blank">Ying Nian Wu</a>
        
      </div>
   <div class="periodical">
      
        <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>,
        2021
  
      </div>  

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://arxiv.org/pdf/2104.01508.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      <a href="https://github.com/AlvinZhuyx/camera_pose_representation" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>How to effectively represent camera pose is an essential problem in 3D computer vision, especially in tasks such as camera pose regression and novel view synthesis. Traditionally, 3D position of the camera is represented by Cartesian coordinate and the orientation is represented by Euler angle or quaternions. These representations are manually designed, which may not be the most effective representation for downstream tasks. In this work, we propose an approach to learn neural representations of camera poses and 3D scenes, coupled with neural representations of local camera movements. Specifically, the camera pose and 3D scene are represented as vectors and the local camera movement is represented as a matrix operating on the vector of the camera pose. We demonstrate that the camera movement can further be parametrized by a matrix Lie algebra that underlies a rotation system in the neural space. The vector representations are then concatenated and generate the posed 2D image through a decoder network. The model is learned from only posed 2D images and corresponding camera poses, without access to depths or shapes. We conduct extensive experiments on synthetic and real datasets. The results show that compared with other camera pose representations, our learned representation is more robust to noise in novel view synthesis and more effective in camera pose regression.</p>
    </div>
    
  </div>
</div>
</li>


    <li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICLR</abbr>
  </div>

  <div id="gao2020learning" class="col-sm-8">
    
      <div class="title">Learning EnergyÂ­-Based Models by Diffusion Recovery Likelihood</div>
      <div class="author">
                <em>Ruiqi Gao</em>, Yang Song, <a href="https://cs.stanford.edu/~poole/">Ben Poole</a>, <a href="http://www.stat.ucla.edu/~ywu/" target="_blank">Ying Nian Wu</a>, and <a href="http://dpkingma.com/" target="_blank"> Diederik P. Kingma</a>
        
      </div>
    <div class="periodical">
      
        <em>Ninth International Conference of Learning Representations (ICLR)</em>,
        2021
  
      </div> 

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://arxiv.org/pdf/2012.08125.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      <a href="https://github.com/ruiqigao/recovery_likelihood" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p>While energy-based models (EBMs) exhibit a number of desirable properties, training and sampling on high-dimensional datasets remains challenging. Inspired by recent progress on diffusion probabilistic models, we present a diffusion recovery likelihood method to tractably learn and sample from a sequence of EBMs trained on increasingly noisy versions of a dataset. Each EBM is trained with recovery likelihood,  which maximizes the conditional probability of the data at a certain noise level given their noisy versions at a higher noise level. Optimizing recovery likelihood is more tractable than marginal likelihood, as sampling from the conditional distributions is much easier than sampling from the marginal distributions. After training, synthesized images can be generated by the sampling process that initializes from Gaussian white noise distribution and progressively samples the conditional distributions at decreasingly lower noise levels.  Our method generates high fidelity samples on various image datasets. On unconditional CIFAR-10 our method achieves FID 9.58 and inception score 8.30, superior to the majority of GANs. Moreover, we demonstrate that unlike previous work on EBMs, our long-run MCMC samples from the conditional distributions do not diverge and still represent realistic images, allowing us to accurately estimate the normalized density of data even for high-dimensional datasets.</p>
    </div>
    
  </div>
</div>
</li>

</ol>

</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    

  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="./js/mansory.js" type="text/javascript"></script>


  


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-180825462-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-180825462-1');
</script>


<!-- Load Common JS -->
<script src="./js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="./js/dark_mode.js"></script>


</html>
