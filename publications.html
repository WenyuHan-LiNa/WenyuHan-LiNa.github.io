
<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Wenyu Han| publications</title>
<meta name="description" content="Wenyu Han's academic website.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="main.css">

<link rel="canonical" href="publication">

<!-- Theming-->


    
<!-- MathJax -->
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       <span class="font-weight-bold">Wenyu Han</span>
      </a>
      
      <!-- Navbar Toogle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="index.html">
              About
              
            </a>
          </li>
          
          <!-- Blog -->
          <!--  <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
           -->
          <!-- Other pages -->
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="publications.html">
                Publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" href="award.html">
              Awards
              
            </a>
        </li>

          <li class="nav-item ">
              <a class="nav-link" href="Wenyu_Han_CV.pdf">
                CV                
              </a>
          </li>
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
  </header>

  <article>
    <!-- An up-to-date list is available on <a href="https://scholar.google.com/citations?user=VdlgOXoAAAAJ&hl=en" target="\_blank">Google Scholar</a> -->
<div class="publications">
  <ol class="bibliography">

 <li><div class="row">
  <div class="col-sm-4">
    <img class="img-fluid img-rounded" src="./photos/teaser_figure_SNAC.PNG" style="border:1px solid black" alt="">
    <!-- <img class="img-fluid z-depth-1 rounded" src="./photos/teaser_figure_SNAC.png"> -->
  </div>
  <div id="gao2020v1" class="col-sm-8">
    
      <div class="title">Learning Simultaneous Navigation and Construction in Grid Worlds</div>
      <div class="author">
            <a href="https://www.linkedin.com/in/WenyuHan0616/">Wenyu Han</a>, Haoran Wu, Eisuke Hirota, Alexander Gao, Lerrel Pinto, Ludovic Righetti, <a href="https://engineering.nyu.edu/faculty/chen-feng">Chen Feng</a>
        
      </div>
   <div class="periodical">    
        <em>The Eleventh International Conference on Learning Representations (ICLR)</em>, 2023
      </div>  

    <div class="links">
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://openreview.net/forum?id=NEtep2C7yD" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      <a href="https://ai4ce.github.io/SNAC/" class="btn btn-sm z-depth-0" role="button" target="_blank">Project</a>
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p> We propose to study a new learning task, mobile construction, to enable an agent to build designed structures in 1/2/3D grid worlds while navigating in the same evolving environments. Unlike existing robot learning tasks such as visual navigation and object manipulation, this task is challenging because of the interdependence between accurate localization and strategic construction planning. In pursuit of generic and adaptive solutions to this partially observable Markov decision process (POMDP) based on deep reinforcement learning (RL), we design
        a Deep Recurrent Q-Network (DRQN) with explicit recurrent position estimation in this dynamic grid world. Our extensive experiments show that pre-training this position estimation module before Q-learning can significantly improve the construction performance measured by the intersection-over-union score, achieving the best results in our benchmark of various baselines including model-free and model-based RL, a handcrafted SLAM-based policy, and human players. <p>
    </div>
  </div>
</div>
</li>


 <li><div class="row">
  <div class="col-sm-4">
    <img class="img-fluid img-rounded" src="./photos/teaer_figure_spare3d.PNG" style="border:1px solid black" alt="">
    <!-- <img class="img-fluid z-depth-1 rounded" src="./photos/teaer_figure_spare3d.PNG"> -->
  </div>
  <div id="gao2021grid" class="col-sm-8">
    
      <div class="title">SPARE3D: A Dataset for SPAtial REasoning on Three-View Line Drawings</div>
      <div class="author">
            <a href="https://www.linkedin.com/in/WenyuHan0616/">Wenyu Han*</a>, Siyuan Xiang*, Chenhui Liu, Ruoyu Wang, <a href="https://engineering.nyu.edu/faculty/chen-feng">Chen Feng</a>   
      </div>
   <div class="periodical">
      
        <em>Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2020
  
      </div>  

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Han_SPARE3D_A_Dataset_for_SPAtial_REasoning_on_Three-View_Line_Drawings_CVPR_2020_paper.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      <a href="https://ai4ce.github.io/SPARE3D" class="btn btn-sm z-depth-0" role="button" target="_blank">Project</a>
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p> Spatial reasoning is an important component of human intelligence. We can imagine the shapes of 3D objects and reason about their spatial relations by merely looking at their three-view line drawings in 2D, with different levels of competence. Can deep networks be trained to perform spatial reasoning tasks? How can we measure their “spatial intelligence”? To answer these questions, we present the SPARE3D dataset. Based on cognitive science and psychometrics, SPARE3D contains three types of 2D-3D reasoning tasks on view consistency, camera pose, and shape generation, with increasing difficulty. We then design a method to automatically generate a large number of challenging questions with ground truth answers for each task. They are used to provide supervision for training our baseline models using state-of-the-art architectures like ResNet. Our experiments show that although convolutional networks have achieved superhuman performance in many visual learning tasks, their spatial reasoning performance in SPARE3D is almost equal to random guesses. We hope SPARE3D can stimulate new problem formulations and network designs for spatial reasoning to empower intelligent robots to operate effectively in the 3D world via 2D sensors.<p>
    </div>
    
  </div>
</div>
</li>


<li><div class="row">
  <div class="col-sm-4">
    <img class="img-fluid img-rounded" src="./photos/teaer_figure_realcity3d.PNG" style="border:1px solid black" alt="">
    <!-- <img class="img-fluid z-depth-1 rounded" src="./photos/teaer_figure_realcity3d.PNG"> -->
  </div>

  <div id="zhu2021learning" class="col-sm-8">
    
      <div class="title">Simplified City Generation Using Auto-Encoding Tree</div>
      <div class="author">
                <a href="https://www.linkedin.com/in/WenyuHan0616/">Wenyu Han</a>, Congcong Wen, Lazarus Chok, Yan Liang Tan, Sheung Lung Chan, Hang Zhao, <a href="https://engineering.nyu.edu/faculty/chen-feng">Chen Feng</a>        
      </div>
   <div class="periodical">
      
        <em>International Society for Photogrammetry and Remote Sensing (Under review on ISPRS)</em>,
        2023
  
      </div>  

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
      <!-- <a href="https://arxiv.org/pdf/2104.01508.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a> -->
      <a href="https://ai4ce.github.io/RealCity3D/" class="btn btn-sm z-depth-0" role="button" target="_blank">Project</a>
    </div>

    <!-- Hidden abstract block -->
    <div class="abstract hidden">
      <p> Existing 3D shape datasets in the research community are generally limited to objects or scenes at the home level. City level shape datasets are rare due to the difficulty in data collection and processing. However, such datasets uniquely present a new type of 3D data with a high variance in geometric complexity and spatial layout styles, such as residential/historical/commercial buildings and skyscrapers. This work focuses on collecting such data, and proposes city generation as new tasks for data-driven content generation. Thus, we collect over 1,000,000 geo-referenced 3D building models from New York City and Zurich. We benchmark various baseline performance on two challenging tasks: (1) city layout generation, and (2) building shape generation. Moreover, we propose an auto-encoding tree neural network for 2D building footprint and 3D building cuboid generation. The dataset, tools, and algorithms will be released to the community. <p>
    </div>
    
  </div>
</div>
</li>

</ol>

</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    

  </body>

  <!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="./js/mansory.js" type="text/javascript"></script>


  


<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-180825462-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-180825462-1');
</script>


<!-- Load Common JS -->
<script src="./js/common.js"></script>

<!-- Load DarkMode JS -->
<script src="./js/dark_mode.js"></script>


</html>
